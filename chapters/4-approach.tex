\chapter{Approach}\label{chap:approach}

\section{Problem Definition}
In spite of the fact that JavaScript was originally intended for simple web-pages scripting, it's popularity has increased over the last years, being the most commonly used programming language among professional developers in 2018. Development of robust and high-quality frameworks such as jQuery, AngularJS, React or Vue.js contributed to JavaScript being the leading programming language for client-side development. 

Moreover, several back-end applications are being written in JavaScript using Node.js, thus unifying the programming languages of client and back-end code. Companies with architectures based on concepts such as serverless and microservices are moving traditional back-end code written in Java, Python or PHP to the cloud and replacing it by small compute services, like AWS Lambda or Google Cloud Functions, or directly by cloud managed services. It is very common that development teams decide to write the compute services in Node.js, thus reducing the technological stack.

However, JavaScript was not intented for developing large-scale applications. Lack of good interface descriptions using types and unintuitive type coercion have been slowing development of JavaScript applications.

The TypeScript programming language is a superset of JavaScript with optional type annotations that compiles to plain JavaScript. It has become a widely used alternative for JavaScript. It enables IDEs to perform code intelligence tasks such as code completion, code navigation or refactoring and it rules out possible run-time errors through static type checking.

Aware that types are important for developing maintainable software systems, several industrial developers started using TypeScript in JavaScript projects. However, despite TypeScript's popularity, many new and existing JavaScript Libraries are still being written in pure JavaScript.

The possibility of using exissting JS libraries in TypeScript projects is critical for a smooth transition and for its adoption in industrial development. TypeScript enables it through \textit{declaration files}, a typed description of the library's API. A public repository, DefinitelyTyped \citep{definitely-typed-repository}, contains declaration files for more than 6000 JS Libraries. 71\% of the top 1000 depended-upon packages have their corresponding declaration file in DefinitelyTyped, as explained in \chapref{chap:background}.

Unfortunately, such files are written and maintained manually, which is tedious, error prone and highly time consuming. The evolution of the declaration files does not follow in some cases the continous development of the corresponding libraries. As a result, some declaration files end up being out of date, thus hindering their usability. Mismatches between the declaration files and the actual JavaScript Library code have a negative impact on developers. Type checking messages and IDE code intelligence features are not accurate, thus increasing developing costs, generating actually more difficulties than before migrating to TypeScript.

Declaration files are critical for TypeScript projects. TypeScript's popularity increase and the continuous growth of packages uploaded to the NPM registry, surpassing \textit{1 million} packages by June 2019, indicate that mismatches between declaration files and JavaScript implementations will likely grow. This Thesis tackles the declaration file generation problem and proposes a solution for assiting programmers in creating TypeScript Declaration Files from JavaScript code and keeping them up to date after.

\todo{Agregar una imagen de un modulo simple con codigo JavaScript y que del otro lado salga el declaration file.}

\section{TypeScript Declaration Files Generation Method}

We introduce a \textit{TypeScript Declaration Files Generation Method}, \mintinline{text}{dts-generate}, which generates a valid TypeScript Declaration File for a specific JavaScript Library uploaded to the NPM Registry, as explained in \figref{fig:tsd_generation_method_block_diagram}.

\input{figures/approach/typescript-declaration-files-generation-method/typescriptDeclarationFilesGenerationMethodBlockDiagram.tex}

The method consists of a continuous refinement process. It generates a TypeScript Declaration File based on data flow and type information gathered at run-time from a code base that executes the JavaScript Library. The code base is expanded by a Symbolic Execution Engine that generates test cases using the generated type definitions. As a result, new execution paths are explored, gathering new run-time information and thus refining the declaration file in every iteration.

Following the goal of easing and automating the generation of TypeScript Declaration Files for existings JavaScript Libraries, the method receives the name of the JavaScript Library published to the NPM Registry as an input argument and returns the corresponding TypeScript declaration file.

The declaration file returned by the method is valid and fully functional, making it suitable for being used within the development process. It contains no errors and matches the structure of the JavaScript Library under analysis, so that the JavaScript code generated after compilation runs. The conducted experiments included tests that consisted on replacing a specific type definition from DefinitelyTyped \citep{definitely-typed-repository} with the one generated in the experiments: TypeScript compilation was sucessful, the generated JavaScript code ran without errors and code intelligence features performed by IDEs like code completion worked as expected.

The feedback loop was not included in the implementation, though. As explained, exploring new execution paths by creating new test cases will refine the declaration files: new types will be assigned to different variables, new interfaces will be detected and existing interfaces will be defined more accurately by detecting new properties. From an incremental point of view, generating the declaration files from run-time information has to be developed in a first place. A declaration file must exist first so that it can be refined afterwards.

For that reason, the decision was to keep the focus on building an end-to-end architecture that supports the generation of valid declaration files for a specific JavaScript Library. The proposed architecture supports a future addition of the refinement loop, without modifying the existing blocks. The Symbolic Execution Engine will expand the existing code base by generating new test cases. The actual generation of declaration files remains unmodified. 

\subsection{Implementation}
As explained before, the DefinitelyTyped Repository is the official repository for finding declaration files for existing JavaScript Libraries. The \textit{TypeScript Declaration Files Generation Method} is intended to be used on existing, published npm packages. The generated output TypeScript declaration file is a valid file which can be used for development and uploaded to the DefinitelyTyped Repository.

Code examples that execute the JavaScript Library are needed to extract the run-time information via code instrumentation. It is achieved by retrieving the examples provided in the README files of the repositories of the different libraries. This is generally the place where developers explicitely show how to use their code. It showed to be an appropriate and pragmatic way of extracting the developer's intention and providing an useful initial code base with meaningful examples, thus avoiding a possible cold start problem. 

The examples and the code base of the library are instrumented with Jalangi \citep{DBLP:conf/sigsoft/SenKBG13}\citep{DBLP:conf/sigsoft/SenKBG13a} to gather data flow information and type information at runtime. Jalangi is a dynamic analysis configurable framework that provides several analysis modules that were extended as needed to retrieve the required run-time information, which is then saved to an output JSON file. This block is written in JavaScript and it runs in Node.js within a Docker container.

A second independent block uses the run-time information to generate a TypeScript Declaration File. It infers the overall structure of the JS Library, the interfaces and the types from the JSON file. This block is a Node.js application written in TypeScript that also runs within a Docker container.

The signatures obtained from the generated declaration file are used to generate pre and post conditions on a Symbolic Execution Engine in order to build different test cases that explore new execution paths. The code from the test cases is then added to the existing code base and the declaration file is generated again using an expanded code base.

Running the TypeScript Declaration File Generation Tool with the same run-time information as input will always produce the same result. If new execution paths are covered by the test cases, new run-time information will be gathered and the declaration file will change accordingly. In order to obtain a sound analysis, the feedback loop would be iterated until the generated declaration files in consecutive iterations do not differ. However, by trading soundness for scalability, the overall procedure can be stopped either using a loop bound, a time bound or an heuristics mechanism. 

The command line interface was inspired in the \mintinline{text}{dts-gen} \citep{dts-gen} package, a declaration files generator developed by Microsoft which is meant to be used as a starting point for writing declaration files. It can be seen in \coderef{code:dts-generate-example} that invoking the package is very simple and the only required argument is the name of the module published to the npm registry.

\begin{code}
  \begin{bashinline}
$ ./dts-generate abs
$ cat output/abs/index.d.ts 
export = Abs;

declare function Abs(input: string): string;

    \end{bashinline}
  \caption[Declaration file generation example]{\textbf{dts-generate usage} - Example of how to generate a declaration file for module \mintinline{text}{abs}.}
  \label{code:dts-generate-example}
\end{code}

\todo{Agregar una imagen mostrando que es un unico script que hace todo. Mostrar imagenes de docker mostrando en qué está escrito cada cosa.}

\section{Initial code base} \label{sec:initial-code-base}
To extract run-time information of a JavaScript Library, it is necessary, by definition, to actually execute the code. It is not enough to instrument the source files of the library. The analysis modules provided by Jalangi to gather information are only triggered if the instrumented code gets executed.

We decided to extract the code examples from the Readme files of the repository associated to the NPM Package. Readme files are usually used by developers for briefly describing what the code does, what problem it solves, how to install the application, how to build the code, etc. It is very common that developers provide code examples in the readme files to show how the code works and how to use it. This is specially true for NPM Packages, which are in general created to solve a specific problem of JavaScript development.

Obtaining code examples for a specific NPM Package is achieved in three steps:
\begin{enumerate}
  \item Obtaining the repository from the package.
  \item Retrieving the README file from the repository.
  \item Extract the code examples from the README file.
\end{enumerate}

\subsection{Repository}
The \mintinline{text}{npm view} command shows data about a package. It is possible to retrieve a specific field of the package registry by specifying fhe field name after the package descriptor. For example to retrieve information about the \textit{lodash} package, the following command can be used: \mintinline{text}{npm view lodash}.

For this particular case, only the url of the repository associated with the package is needed. This can be achieved by adding the correponding field name: \mintinline{text}{npm view <PACKAGE> repository.url}.

\begin{bashinline}
$ npm view npm repository.url
git+https://github.com/npm/cli.git

$ npm view lodash repository.url
git+https://github.com/lodash/lodash.git

$ npm view jquery repository.url$
git+https://github.com/jquery/jquery.git
\end{bashinline}

\subsection{Readme files}
The url for downloading a raw file from a Github Repository is the following:

\begin{bashinline}
https://raw.githubusercontent.com/THE-REPOSITORY/master/PATH-TO-FILE
\end{bashinline}

After the repository url is extracted from the npm package, the url for downloading the readme file needs to be constructed performing some string manipulation. Finally, the readme file is obtained with a simple \mintinline{text}{curl} or \mintinline{text}{wget} command.

\begin{bashinline}
$ npm view abs repository.url
git+ssh://git@github.com/IonicaBizau/abs.git

$ curl -L -o readme.md --fail \
    https://raw.githubusercontent.com/IonicaBizau/abs/master/README.md
\end{bashinline}

\subsection{Code examples}
Readme files are written using Markdown\footnote{https://www.markdownguide.org}, a very common lightweight and simple markup language. GitHub or BitBucket will convert the readme files into HTML automatically and render them when accessing the repository through a web browser.

It is very common to write code examples within code blocks indicating the programming language, so that it gets highlighted with the specific syntax. The Markdown identifiers for JavaScript are \mintinline{text}{js} or \mintinline{text}{javascript}. The code examples are finally retrieved by filtering the content within the corresponding code blocks.

\begin{textinline}
$ cat example-readme.md
# Description
This is an example that shows how to use console.log().

```js
var a = "Hello World!";

function f(s) {
	console.log(s);
}

f(a);
```

$ cat example-readme.md | \
  sed 's/```javascript/```js/g' | \
  sed -n '/^```js/,/^```/ p' > example.js

$ node example.js
Hello World!
\end{textinline}

\section{Run-time Information Gathering} \label{run-time-information-gathering}
As shown in a simple example in \figref{fig:run-time-information-gathering-simple-example}, run-time analysis will gather information such as:

\begin{enumerate}
  \item Function \mintinline{text}{f} got invoked with parameters \mintinline{text}{a} and \mintinline{text}{b} with types \mintinline{text}{string} and \mintinline{text}{number}.
  \item Property or method \mintinline{text}{foo} of parameter \mintinline{text}{a} of function \mintinline{text}{f} was accessed within the function.
  \item Parameter \mintinline{text}{a} of function \mintinline{text}{f} was used as operand for operator \mintinline{text}{==}.
\end{enumerate}

The dynamic analysis framework used for gathering this kind of information is Jalangi. As explained in \secref{sec:jalangi}, the configurable analysis modules enable programming custom callbacks that get triggered with virtually any JavaScript event. The events that are observed are:
\begin{enumerate}
  \item Binary operations, like \mintinline{text}{==}, \mintinline{text}{+} or \mintinline{text}{===}.
  \item Variable declaration.
  \item Function, method, or constructor invocation.
  \item Access to an object's property.
  \item Unary operations, like \mintinline{text}{!} or \mintinline{text}{typeof}.
\end{enumerate}

The implementation stores these observations as entities called \textit{interactions}. As explained later in \secref{sec:run-time-analysis}, they are used for translating, modifying and aggregating Jalangi's raw event information in order to get an application specific data representation.

The main goal of the run-time analysis is to gather information useful for determining a function's signature. Therefore, observations need to get associated with a function's argument. The implementation wraps variables around Proxy Objects to store tracking data, hereby enabling to associate the observation with a specific argument. The effect is reverted using Jalangi's callbacks to modify the behaviour of the affected operators, such as \mintinline{text}{===} or \mintinline{text}{typeof}.

Jalangi fails to instrument some JavaScript Libraries. No effort was made in trying to fix failing instrumentation. Failing JS Libraries were ommited from the analysis by providing a list with the names of the modules that should not be instrumented.

Each function is given an unique key, which is used as the primary key of a map where the run-time information is stored. Each function has an array of arguments and each interaction gets associated with an argument. The map is finally returned as a JSON file that can be used for later processing.

The tool is written in JavaScript and runs in Node.js within a Docker container.

\input{figures/approach/run-time-information-gathering/simple-example.tex}

\subsection{Analysis} \label{sec:run-time-analysis}
The provided analysis module implements the following Jalangi callbacks, which were explained in detail in \secref{sec:jalangi}:
\begin{itemize}
  \item binaryPre()
  \item declare()
  \item getFieldPre()
  \item setFieldPre()
  \item functionEnter()
  \item functionExit()
  \item invokeFun()
  \item invokeFunPre()
  \item unaryPre()
  \item write()
\end{itemize}

They enable observation of all JS operations considered relevant. Every invoked function is given an unique identifier and information for each argument of every function gets stored. The entities \mintinline{text}{FunctionContainer}, \mintinline{text}{ArgumentContainer} and \mintinline{text}{Interaction} are introduced to support the representation of the gathered run-time information. 

Run-time information is stored in a map that contains objects of type \mintinline{text}{FunctionContainer}.
This entity contains static information about the function as well as implementation specific data needed for generating the right type of declaration file, as explained in \secref{sec:declaration-files-background}. Each field of the entity is explained in \coderef{code:function-container}.

\begin{code}
  \jscode{code/run-time-information-gathering/analysis/function-container.js}
  \caption[FunctionContainer object]{\textbf{\mintinline{text}{FunctionContainer} object} - \mintinline{text}{FunctionContainer} is the main entity in the map where the run-time information gets gathered. It contains implementation specific information for the declaration files generation. Entities of type \mintinline{text}{ArgumentContainer} get appended to the \mintinline{text}{args} property.}
  \label{code:function-container}
\end{code}

Moreover, as explained in \coderef{code:argument-container}, the \mintinline{text}{ArgumentContainer} object works as a container for all interactions recorded for that argument. Additionally, it contains simple information about the argument itself, like the index or the name given in the function declaration.

\begin{code}
  \jscode{code/run-time-information-gathering/analysis/argument-container.js}
  \caption[ArgumentContainer object]{\textbf{\mintinline{text}{ArgumentContainer} object} - The \mintinline{text}{ArgumentContainer} object works mainly as a container for all relevant observations regarding that argument.}
  \label{code:argument-container}
\end{code}

Finally, observations on the arguments of a function are stored as objects of type \mintinline{text}{Interaction}. They have to be always associated to an \mintinline{text}{ArgumentContainer} object or to another \mintinline{text}{Interaction}. They are explained in detail in \secref{sec:run-time-interactions}.

\subsection{Interactions} \label{sec:run-time-interactions}
Jalangi enables the developer to create custom analysis modules by implementing the callbacks that are relevant for the application. However, the callbacks belong to an abstraction layer that is not aware of the actual implementation. 

Observations of the arguments are stored as \mintinline{text}{Interactions}. They represent the relevant observation data that needs to be extracted for the purpose of best describing a function in order to generate a TypeScript declaration file.

The object \mintinline{text}{Interaction} is associated to an \mintinline{text}{ArgumentContainer}. If the \mintinline{text}{ArgumentContainer} does not exist when the Jalangi callback is triggerd, the \mintinline{text}{Interaction} is not saved. The main goal of gathering run-time information is to describe a function and its arguments. Thus, callbacks triggered on variables that are not arguments of functions are ignored, as shown in \coderef{code:ignored-observations}. The mechanism to map an observation with an \textit{ArgumentContainer} is described in detail in \secref{sec:run-time-wrapper-objects}

\begin{code}
  \jscode{code/run-time-information-gathering/analysis/ignored-observations.js}
  \caption[Ignored observations]{\textbf{Ignored observations} - Variable \mintinline{text}{b} gets declared within the scope of function \mintinline{text}{foo}. Therefore, no observation on it gets stored.}
  \label{code:ignored-observations}
\end{code}

\subsubsection{\textit{inputValue} interaction}
It is the most simple interaction. As shown in \figref{fig:run-time-information-gathering-input-value}, it gets triggered when a function is invoked and it stores the input value of a specific argument. If a function gets invoked several times, different interactions get stored, each one of them with a different \mintinline{text}{traceId}.

\input{figures/approach/run-time-information-gathering/analysis/input-value.tex}

\subsubsection{\textit{getField} interaction}
This interaction gets triggered whenever a property of an object gets accessed, either if the get field operation is \mintinline{text}{obj.field} or \mintinline{text}{obj['field']}. As shown in \figref{fig:run-time-information-gathering-get-field}, the name of the accessed field and the type of the actual property get stored.

It should be noted that the field \mintinline{text}{returnTypeOf} represents the type of the accessed property at the time when the interaction gets triggered. The accessed property may somehow get modified afterwards, which will not modify the existing interaction. If the property gets accessed again, a new interaction with a new \mintinline{text}{returnTypeOf} value will be added, as shown in \coderef{code:get-field-changing-at-runtime}.

\begin{code}
  \jscode{code/run-time-information-gathering/analysis/get-field-changing-at-runtime.js}
  \caption[Modified accessed property]{\textbf{Modified accessed property} - Variable \mintinline{text}{b} gets declared within the scope of function \mintinline{text}{foo}. Therefore, no observation on it gets stored.}
  \label{code:get-field-changing-at-runtime}
\end{code}

\input{figures/approach/run-time-information-gathering/analysis/get-field.tex}

\subsubsection{\textit{methodCall} interaction}
This interaction gets triggered with the invocation of an object's method. As explained in \figref{fig:run-time-information-gathering-method-call}, information about the method itself is stored as another \mintinline{text}{FunctionContainer} in the overall map. The reference to the \mintinline{text}{FunctionContainer} is achieved through the properties \mintinline{text}{functionId} and \mintinline{text}{traceIdInTargetFunction}.

\input{figures/approach/run-time-information-gathering/analysis/method-call.tex}

\subsubsection{\textit{setField} interaction}
The trigger for this interaction is writing an object's property, either by accessing the field as \mintinline{text}{obj.field = 1} or \mintinline{text}{obj['field'] = 1}. It can be seen in \figref{fig:run-time-information-gathering-set-field} that the interaction contains the name of the property to be written and the type of the value to be stored.

\input{figures/approach/run-time-information-gathering/analysis/set-field.tex}


\subsubsection{\textit{usedAsArgument} interaction}
The run-time information is stored in a map with one \mintinline{text}{FunctionContainer} entry per function. As seen in \figref{fig:run-time-information-gathering-used-as-argument}, an argument of function \mintinline{text}{foo()} is used as parameter to invoke a second function \mintinline{text}{bar()}. Interactions triggered within function \mintinline{text}{bar()} are going to be stored within the \mintinline{text}{FunctionContainer} corresponding to function \mintinline{text}{bar()}, i.e. not the one associated to function \mintinline{text}{foo()}.

However, for the example provided in \figref{fig:run-time-information-gathering-used-as-argument} it is relevant to also associate interactions triggered within function \mintinline{text}{bar()} to the function \mintinline{text}{foo()}, since they can  be useful for describing the argument of \mintinline{text}{foo()} more accurately.

Therefore, \mintinline{text}{usedAsArgument} interaction is introduced. It gets triggered when an argument is used in the invocation of a consecutive function. It serves the purpose of connecting related interactions. As shown in \figref{fig:run-time-information-gathering-used-as-argument}, it mainly contains information for identifying the target \mintinline{text}{FunctionContainer}.

\input{figures/approach/run-time-information-gathering/analysis/used-as-argument.tex}

\subsubsection{\textit{operator} interaction}
Identifying if an argument is used with a specific operator is very important for infering the type of that variable. Relational operators like \mintinline{text}{<, >, <=, >=} are mainly used with type \mintinline{text}{number}. On the other side, operator \mintinline{text}{+} is mainly used with \mintinline{text}{number} or \mintinline{text}{string}. Empirical evidence of how operators are used is presented in \secref{sec:experiments-js-operators-usage}.

The \mintinline{text}{operator} interaction stores the operator being used and the type of the left hand and right hand operands. It also indicates which operand is the one that triggered the interaction. \figref{fig:run-time-information-gathering-operator} provides an example for operator \mintinline{text}{+}.

The supported operators are the ones that trigger Jalangi's \mintinline{text}{binaryPre()} callback. Conditionals are merged into one operator name \mintinline{text}{conditional}, since Jalangi's \mintinline{text}{conditional()} callback does not offer a way of identifying the operator for this cases. Both callbacks are explained in section \secref{sec:jalangi}. Right hand operand is left as \mintinline{text}{undefined} for that case.

\input{figures/approach/run-time-information-gathering/analysis/operator.tex}

\subsubsection{\textit{followingInteractions}}
If a property of an argument is accessed the Jalangi callback \mintinline{text}{getField()} gets triggered and a \mintinline{text}{getField} interaction gets associated to the corresponding \mintinline{text}{ArgumentContainer}. In order to describe the interface of the argument more accurately, it is also relevant to recursively record if properties of the return values are accessed, as explained in \figref{fig:run-time-information-gathering-following-interactions}.

This was implemented by not only mapping the observation with an \mintinline{text}{ArgumentContainer} but also with a \mintinline{text}{getField} or \mintinline{text}{methodCall} interaction. Both \mintinline{text}{ArgumentContainer} and \mintinline{text}{Interaction} implement the \mintinline[breaklines]{javascript}{addInteraction} method, as shown in \coderef{code:add-interaction-example}

\begin{code}
  \jscode{code/run-time-information-gathering/analysis/add-interaction-example.js}
  \caption[addInteraction method]{\textbf{addInteraction method} - Example showing how interactions can be associated with \mintinline{text}{ArgumentContainer} or with another \mintinline{text}{Interaction}.}
  \label{code:add-interaction-example}
\end{code}

\input{figures/approach/run-time-information-gathering/analysis/following-interactions.tex}

\subsubsection{Traces}
Different executions of a function are identified through different \mintinline{text}{traceIds}. Each interaction and return value of a \mintinline{text}{FunctionContainer} stores the corresponding \mintinline{text}{traceId}. The \mintinline{text}{traceId} field enables identifying correlations between input types and return values, as explained in \secref{sec:typescript-overloading}. An example is provided in \figref{fig:run-time-information-gathering-traces}.

\input{figures/approach/run-time-information-gathering/analysis/traces.tex}


\subsection{Wrapper Objects} \label{sec:run-time-wrapper-objects}
An \mintinline{text}{Interaction} needs to be associated to an \mintinline{text}{ArgumentContainer} or to another \mintinline{text}{Interaction}. This means that when Jalangi triggers a callback, it must be determined if that callback is relevant or not, i.e. if that callback refers to an argument of an invoked function. However, this can not be determined by only using the information provided in the different callbacks.

However, Jalangi exposes the actual value affected by the callback. For example, for the \mintinline{text}{getField()} callback triggered by operation \mintinline{javascript}{myObj.prop}, Jalangi does provide the object \mintinline{javascript}{myObj} in the callback.

The solution consists in wrapping every input argument around a Wrapper Object when the function gets invoked. The Wrapper Object will store the reference to the corresponding \mintinline{text}{ArgumentContainer} or \mintinline{text}{Interaction}. Jalangi callbacks will then get triggered on the Wrapper Object instead. A mapping with the corresponding \mintinline{text}{ArgumentContainer} or \mintinline{text}{Interaction} is then straightforward, since the reference can be directly retrieved from the Wrapper Object.

Jalangi enables to modify the behaviour of the original code. Using \mintinline{text}{invokFunPre} and \mintinline{javascript}{declare} callbacks, a function invocation is detected and the arguments of the function are modified in run-time.

Every function invocation generates new Wrapper Objects, which means that a Wrapper Object represents the input argument for a specific invocation. \mintinline{text}{TraceIds} are also stored within these objects.

The solution extends a similar concept already implemented by Jalangi: \mintinline{text}{ShadowObjects}. It is a unique object associated to another object which can store meta-information. However, a \mintinline{text}{ShadowObject} can not be created for primitives values, which is a major drawback. It is indeed relevant to capture, for example, if a \mintinline{text}{number} is being used with a particular operator or if the property \mintinline{text}{length} of a \mintinline{text}{string} is being accessed.

The implemented solution wraps objects around JavaScript Proxies. Primitive values like \mintinline{text}{number} or \mintinline{text}{string} are converted to their native wapper objects, i.e. \mintinline{text}{Number} and \mintinline{text}{String}. Finally, \mintinline{text}{null} and \mintinline{text}{undefined} are converted to empty objects with modified \mintinline{text}{valueOf()} and \mintinline{text}{toString()} methods.

The behaviour of the original code is being explicitely modified. Therefore, original values are used instead for affected operators like \mintinline{text}{===, !==, typeof}, for which wrapper objects will not work as expected. For \mintinline{text}{null} and \mintinline{text}{undefined} wrappers, the original values are used for conditional operators, since the result of the abstract operation \mintinline{text}{ToBoolean} on an object is always \mintinline{text}{true}, as defined in the ECMAScript Language Specification \citep{ecma-script}. This approach could have been used for every operation by using the original value in the affected Jalangi callbacks. However, the implementation is complex and error prone. Instead, it was decided to modify the corresponding methods or specific operators so that they are compliant with JavaScript Type Coercion, which is explained in detail in {sec:background-js-type-coercion}.

\subsection{Output}
Information is stored in a map containing \mintinline{text}{FunctionContainer} entries. When the executions stops, Jalangi's callback \mintinline{text}{endExecution()} is called and the information is saved as a JSON to a file.


\subsection{Blacklisted Modules}
When instrumenting a JS Library, Jalangi will try to instrument all required modules by resolving and finding the modules. Unfortunately, Jalangi's native behaviour is to stop the complete analysis if there is an error in the instrumentation of any of the required modules or in the script itself.

The workaround introduced by the implementation modifies Jalangi's behaviour for failing instrumentation. For a given required module, it first tries to instrument it. If the instrumentation if unsuccesful, it simply skips the instrumentation and returns the original uninstrumented module.

As expected, no Jalangi callbacks will be triggered for that module's code. However, this workaround enables to at least still get run-time information of other required modules by not breaking the complete analysis. As explained in \figref{fig:blacklisted-modules}, instead of stopping the analysis, failing modules are skipped but modules required by them do get instrumented anyway. Modifying Jalangi's instrumentation algorithm is out of the scope of this work.

The application can be invoked by passing an optional argument with the path to a a JSON file containing the list of modules that should not be instrumented.

\input{figures/approach/blacklisted-modules/blacklistedModules.tex}

\section{TypeScript Declaration File Generation}
The actual generation of the declaration file is the next step in the pipeline after gathering the run-time information, as shown in \figref{fig:tsd_generation_method_block_diagram}. It is a lightweight, simple and fast application, which does not interact with the actual JavaScript module at run-time. Instead, it uses the JSON output file containing the run-time information and generates a TypeScript declaration file which is use ready to be used within a TypeScript project. The tool itself is written in TypeScript and runs within a Docker container in NodeJS. 

\subsection{Templates}
TypeScript provides templates for writing declaration files, as explained in \secref{sec:declaration-files-background}. Each template corresponds to a different way of exporting a JS module. The code uses different fields from the \mintinline{text}{FunctionContainer} entity in the run-time information to detect how the module is being used:

\begin{itemize}
  \item \mintinline{text}{requiredModule}: The name of the module that exported the corresponding function. It is useful for processing only functions exported by the module for which the declaration files is being generated.
  \item \mintinline{text}{isExported}: Boolean that indicates whether the function is exported when importing the module.
  \item \mintinline{text}{isConstructor}: Boolean that indicates whether the function was used as a constructor through the \mintinline{text}{new} operator.
  \item \mintinline{text}{constructedBy}: Indicates the \mintinline{text}{functionId} that constructed the object invoking the corresponding function.
\end{itemize}

The following templates were implemented:

\begin{enumerate}
  \item \mintinline{text}{module.d.ts}: It is used when the exported module is a JavaScript object containing several properties and methods. It is the most common used template: more than 70\% of the modules uploaded to DefinitelyTyped are based on this template. The code checks if the exported module is neither a function nor a constructor, i.e. if properties \mintinline{text}{isExported} and \mintinline{text}{isConstructor} are \mintinline{text}{false}. An example is provided in \figref{fig:ts-declaration-file-module-template}.

  \item \mintinline{text}{module-class.d.ts}: As shown in \figref{fig:ts-declaration-file-module-class-template}, this template is used when the exported function is supposed to be used as a constructor with the \mintinline{text}{new} operator. The code will use this template when both the fields \mintinline{text}{isExported} and \mintinline{text}{isConstructor} are true. It should be noted that the module exports only the constructor function. Methods belonging to the class are detected using the \mintinline{text}{constructedBy} field from the run-time data.
  
  \item \mintinline{text}{module-function.d.ts}: It is used when the module exports only a function. The field \mintinline{text}{isExported} field is used to determine whether this templates should be used or not. An example is provided in \figref{fig:ts-declaration-file-module-function-template}. If further interfaces or types are required, they are written within a namespace named like the exported function.
\end{enumerate}

\input{figures/approach/typescript-declaration-files-generation-method/examples/templates/module-template.tex}

\input{figures/approach/typescript-declaration-files-generation-method/examples/templates/module-class-template.tex}

\input{figures/approach/typescript-declaration-files-generation-method/examples/templates/module-function-template.tex}

JavaScript construtors where explained in \secref{sec:background-javascript}. There are built-in functions that are not able to be used as a constructors. For example, if \mintinline{text}{Math} is intended to be used as a constructor with the \mintinline{text}{new} operator, the following error will arise: \mintinline{text}{TypeError: Math is not a constructor}. ES6 arrow functions are not allowed to used as a constructor either. However, for those functions that can be both used as constructors or called as regular functions, there is no difference between them that actually indicate whether a function is intended to be used with the \mintinline{text}{new} operator or not. The choice of using the \mintinline{text}{module-function.d.ts} or the \mintinline{text}{module-class.d.ts} template is made after executing the code and depends on how the function was used.

\coderef{code:typescript-templates-function-as-constructor} exposes a scenario for which a module could be infered as \mintinline{text}{module-function.d.ts} or \mintinline{text}{module-class.d.ts} depending only on how it was executed. Thus, examples that execute the module under analysis by truly representing the developer's intention are crucial for an accurate generation of declaration files and inference of types and interfaces. As explained in \secref{sec:initial-code-base}, this was achieved by extracting the code examples written by the developers from the repositories.

\begin{code}
  \jscode{code/typescript-declaration-file-generation/templates/function-as-constructor.js}
  \caption[Choice between module-function.d.ts or module-class.d.ts]{\textbf{Choice between module-function.d.ts or module-class.d.ts} - If the exported module is used without the \mintinline{text}{new} operator, the \mintinline{text}{module-function.d.ts} template will be used. If used with the \mintinline{text}{new} operator, the \mintinline{text}{module-class.d.ts} template will be applied.}
  \label{code:typescript-templates-function-as-constructor}
\end{code}

\subsection{Interfaces}
Interfaces are created by exploring \mintinline{text}{getField} and \mintinline{text}{methodCall} interactions from the run-time information. The code will gather the interactions for a specific argument and build the interface by incrementally adding new properties. Interactions within the \mintinline{text}{followingInteractions} field are recursively traversed, building a new interface in each recursion level.

An example is provided in \figref{fig:ts-declaration-file-generation-interfaces}. The name given to the interface is based on the name of the input argument.

It can be also seen in \figref{fig:ts-declaration-file-generation-nested-interfaces} that nested interfaces are declared as independent interfaces and then declared as types of the prior interface.

\input{figures/approach/typescript-declaration-files-generation-method/examples/generation-declaration-file-with-interfaces.tex}

\input{figures/approach/typescript-declaration-files-generation-method/examples/generation-declaration-file-with-nested-interfaces.tex}

\subsection{Type inference}
\todo{El tipo se extrae del valor en runtime.}
\subsection{Implementation}
The application runs within a Docker container. \coderef{code:declaration-file-generation-docker} explains how to build and run the application and how to extract the declaration file from the container.

\begin{code}
\begin{bashinline}
$ ./build/build.sh
$ docker run --name generate-declaration-file \
  -v PATH_TO_RUN_TIME_INFORMATION_JSON:/tmp/output.json \
  tsd-generator \
  --module-name calculator \
  -i /tmp/output.json

$ docker cp generate-declaration-file:/usr/local/app/output/. /tmp/ts-declaration-file
$ docker rm generate-declaration-file
$ cat /tmp/ts-declaration-file/calculator/index.d.ts
export function sum(a: number, b: number): number;
export function multiply(a: number, b: number): number;
\end{bashinline}
  \caption[Declaration file generation]{\textbf{Declaration file generation} - The Docker image needs to be built after cloning the repository. Afterwards, the declaration file is generated by the run-time information and then retrieved from the container.}
  \label{code:declaration-file-generation-docker}
\end{code}

\section{Evaluation}
\input{figures/approach/evaluation/evaluationDiagram.tex}
\subsection{Parsing}
\subsubsection{TypeScript Compiler API}
\subsection{Comparison}
\todo{Number of functions}
\todo{Number of parameters}
\todo{Interfaces}
\todo{methodCall}
\todo{usedAsArgument}
\todo{Syntax \& Semantic Errors}